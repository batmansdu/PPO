# PPO
learn the RL algorithm PPO


This repo is a toy implementation of PPO algorithm where many Chinese annotation in the file.
And the code was writting by following the guide of https://github.com/ericyangyu/PPO-for-Beginners. It's very good for RL beginners.
